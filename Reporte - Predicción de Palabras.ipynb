{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"left\">\n",
    "<img align=\"left\" src=\"./Data/logo-alinnco.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maestría en Inteligencia Artificial - Procesamiento de Lenguaje Natural\n",
    "### Profesor: Dr. Gaddiel Desirena López\n",
    "### Integrantes del equipo\n",
    "* Guillermo Betanzos\n",
    "* Luis Landeros\n",
    "* Sergio Rojas\n",
    "* Alberto Torres\n",
    "\n",
    "#### Índice\n",
    "[Objetivo](#objetivo)<br>\n",
    "[Corpus](#corpus)<br>\n",
    "[Tokenización](#tokenizacion)<br>\n",
    "[Modelo](#modelo)<br>\n",
    "[Modelo: Entrenamiento](#entrenamiento)<br>\n",
    "[Modelo: Evaluación](#evaluacion)<br>\n",
    "[Modelo: Pruebas](#pruebas)<br>\n",
    "[Conclusiones](#conclusiones)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='objetivo'>Objetivo</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El procesamiento del lenguaje natural tiene como objetivo fundamental lograr una comunicación maquina-humano similar a la comunicación humano-humano.\n",
    "\n",
    "El objetivo principal del PLN es hacer que las máquinas comprendan textos no estructurados y exigan la información relevante de esos textos. Este se centra en el análisis de las comunicaciones humanas, en concreto de su propio lenguaje. Ante la gran cantidad de información en texto que generamos actualmente, surge la posibilidad de analizarla y aprovecharla. Las técnicas de PLN permiten extraer insights automáticamente de la información disponible en cualquier sector.\n",
    "\n",
    "El objetivo de este proyecto, es el desarrollar una solución utilizando el Procesamiento de Lenguaje Natural para la predicción de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import heapq\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='corpus'>Corpus</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay pasos que puede seguir para preprocesar datos en lenguaje natural, de modo que el modelado que lleve a cabo en sentido descendente sea más preciso. Las opciones comunes de preprocesamiento de lenguaje natural incluyen:\n",
    "* Tokenización\n",
    "* Convertir caracteres a minúsculas\n",
    "* Remoción de palabras vacías\n",
    "* Eliminación de la puntuación\n",
    "* Stemming\n",
    "* Manejo de n-gramas\n",
    "\n",
    "Para la elección del corpus del proyecto se consideró inicialmente el proyecto <a href=\"https://www.gutenberg.org/browse/languages/es\" target=\"_blank\">Gutenberg</a>, desafortunadamente los resultados obtenidos no fueron esperados ya que no se encontró congruencia alguna entre el texto proporcionado al modelo y la salida.\n",
    "\n",
    "En vista de los resultados obtenidos procedimos a buscar corpus que fuesen más ricos en datos, tales como los corpus compuestos por Wikipedia, desafortunadamente las necesidades de recursos para procesar dichos corpus son demandantes en demasía.\n",
    "\n",
    "\n",
    "<img src=\"./Data/memory.png\">\n",
    "<div align=\"center\">Figura 1. Desbordamiento de memoria</div>\n",
    "\n",
    "De tal suerte que dados los resultados en la elección del corpus hasta el momento se procedió a elegir uno que fuese relativamente más pequeño pero con contenido regionalizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 423923\n"
     ]
    }
   ],
   "source": [
    "path = 'lnr.txt'\n",
    "text = open(path, encoding=\"utf-8\").read().lower() + open(\"novelas.txt\", encoding=\"utf-8\").read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='tokenizacion'>Tokenización</a>\n",
    "\n",
    "Antes de realizar una tarea de PLN hay que normalizar el texto, esto incluye 3 actividades:\n",
    "\n",
    "1. Segmentación/tokenización de las palabras.\n",
    "2. Normalización del formato de las plabras\n",
    "3. Segmentación de las oraciones en el texto.\n",
    "\n",
    "Algunos conceptos:\n",
    "\n",
    "* Lema (Lemma): Palabras que comparten un tronco común, que hacen referencia al mismo concepto básico\n",
    "\n",
    "    Ejemplo: gato, gatos, gata son palabras con el mismo lema.\n",
    "    \n",
    "\n",
    "* Forma de la palabra (Wordform): La forma completa de la palabra.\n",
    "\n",
    "    Ejemplo: gato, gatos, gata son palabras con distinta forma (different wordform)\n",
    "    \n",
    "\n",
    "* Tipo (Type): Un elemento del vocabulario.\n",
    "\n",
    " \n",
    "* Token: Una instancia de un tipo en un texto dado.\n",
    "\n",
    "\n",
    "Se realiza la tokenización del corpus/dataset en cada palabra que lo compone excluyendo la presencia de caracteres especiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RegexpTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-59e2cd994368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\b\\w+\\b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RegexpTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\b\\w+\\b')\n",
    "words = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = np.unique(words)\n",
    "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A través de la Ingeniería Funcional, la cuál es el proceso de creación de nuevas funciones a partir de datos sin procesar para aumentar el poder predictivo del algoritmo de aprendizaje, se definirá una longitud de palabra que representará el número de palabras anteriores las cuales determinarán la siguiente palabra. \n",
    "\n",
    "Asimismo definimos palabras previas para mantener cinco palabras anteriores y sus siguientes palabras correspondientes en la lista de palabras siguientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_LENGTH = 5\n",
    "prev_words = []\n",
    "next_words = []\n",
    "for i in range(len(words) - WORD_LENGTH):\n",
    "    prev_words.append(words[i:i + WORD_LENGTH])\n",
    "    next_words.append(words[i + WORD_LENGTH])\n",
    "print(prev_words[0])\n",
    "print(next_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(prev_words), WORD_LENGTH, len(unique_words)), dtype=bool)\n",
    "Y = np.zeros((len(next_words), len(unique_words)), dtype=bool)\n",
    "for i, each_words in enumerate(prev_words):\n",
    "    for j, each_word in enumerate(each_words):\n",
    "        X[i, j, unique_word_index[each_word]] = 1\n",
    "    Y[i, unique_word_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='modelo'>Modelo</a>\n",
    "\n",
    "Para el modelo de predicción de palabra haremos uso de Redes Neuronales Recurrentes (RNN - Recurrent Neural Networks), en este caso muy particular la arquitectura de aprendizaje profundo LSTM (long short-term memory).\n",
    "\n",
    "Las RNN son aplicables a cualquier dato que ocurre en una secuencia tales como las series de tiempo financieras, niveles de inventario, tráfico y el clima; esencialmente todo lo que involucre modelos de predicciones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Data/dl.png\">\n",
    "<div align=\"center\">Figura 2. Deep Learning</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes LSTM fueron introducidas por Sepp Hochreiter y Jürgen Schmidhuber en 1997, pero hoy en día se utilizan más ampliamente en aplicaciones de aprendizaje profundo de Procesamiento de Lenguaje Natural (PNL/NLP). \n",
    "\n",
    "La estructura básica de una capa LSTM es la misma que la de las capas recurrentes simples, reciben entradas de la secuencia de datos (por ejemplo, un token particular de un documento en lenguaje natural) y también reciben entradas del punto de tiempo anterior en la secuencia. \n",
    "\n",
    "La diferencia es que dentro de cada celda en una capa recurrente simple (por ejemplo, SimpleRNN () en Keras), encontrará una única función de activación de red neuronal, como una función tanh, que transforma las entradas de la celda RNN para generar su salida. \n",
    "\n",
    "En contraste, las celdas de una capa LSTM contienen una estructura mucho más compleja, poseen conexiones de retroalimentación a diferencia de las redes más tradicionales \"feed forward\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(WORD_LENGTH, len(unique_words))))\n",
    "model.add(Dense(len(unique_words)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='entrenamiento'>Modelo: Entrenamiento</a>\n",
    "\n",
    "Como parte de la implementación del modelo se decidió por el optimizador RMSprop (root mean square propagation) el cuál fue desarrollado por Geoff Hinton aproximadamente al mismo tiempo que AdaDelta.\n",
    "\n",
    "Funciona de manera similar excepto que retiene el parámetro de tasa de aprendizaje η. Tanto RMSProp como AdaDelta implican un hiperparámetro adicional ρ (rho), o tasa de decaimiento, que es análogo al valor β del impulso y que guía el tamaño de la ventana para la media móvil. Los valores recomendados para los hiperparámetros son ρ = 0,95 para ambos optimizadores y el ajuste η = 0,001 para RMSProp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=50, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_words = np.unique(words)\n",
    "#unique_word_index = dict((c, i) for i, c in enumerate(unique_words))\n",
    "\n",
    "model.save('keras_next_word_model.h5')\n",
    "pickle.dump(history, open(\"history.p\", \"wb\"))\n",
    "model = load_model('keras_next_word_model.h5')\n",
    "history = pickle.load(open(\"history.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')Guillermo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, WORD_LENGTH, len(unique_words)))\n",
    "    for t, word in enumerate(text.split()):\n",
    "        print(word)\n",
    "        x[0, t, unique_word_index[word]] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_input(\"la niña era\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completions(text, n=3):\n",
    "    if text == \"\":\n",
    "        return(\"0\")\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [unique_words[idx] for idx in next_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"no funciona\"\n",
    "print(\"correct sentence: \",q)\n",
    "seq = \" \".join(tokenizer.tokenize(q.lower())[0:5])\n",
    "print(\"Sequence: \",seq)\n",
    "print(\"next possible words: \", predict_completions(seq, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='conclusiones'>Conclusiones</a>\n",
    "\n",
    "Con el propósito de dar a conocer el estado actual del Procesamiento del Lenguaje Natural se han definido, de forma muy concisa, los principales conceptos y técnicas asociados a esta disciplina, que además se ha desarrollado a lo largo de este proyecto escolar.\n",
    "\n",
    "Así mismo, se ha comprobado que el PLN es una disciplina viva y en pleno desarrollo, con multitud de retos que superar fruto de la ambigüedad subyacente al lenguaje natural. El empleo del lenguaje le permite al hombre trasmitir sus conocimientos, sentimientos, sensaciones, emociones, y estados de ánimo, por lo que han sido varios los sistemas informáticos inteligentes que se han desarrollado y continuan en evolución continua que emplean el procesamiento del lenguaje natural, para una mayor comprensión y mejoría en el ámbito de las tecnologías de información."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
